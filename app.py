import streamlit as st
import pandas as pd
import pdfplumber
import io
from datetime import datetime
import re
import calendar

def extract_text_from_pdf(pdf_file):
    """PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    text = ""
    with pdfplumber.open(pdf_file) as pdf:
        for page in pdf.pages:
            text += page.extract_text() + "\n"
    return text

def parse_suica_data(text, user_name="ç”°ä¸­å¤ªéƒ", valid_stations=None,
                    target_year=None, target_month=5, exclude_keywords=None):
    """Suicaåˆ©ç”¨å±¥æ­´ãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æã—ã¦DataFrameã«å¤‰æ›"""
    if valid_stations is None:
        valid_stations = ["äº”åç”°"]

    if exclude_keywords is None:
        exclude_keywords = ["ç‰©è²©", "ï½¶ï½°ï¾„ï¾", "ãƒ¢ãƒã‚¤ãƒ«"]

    if target_year is None:
        target_year = datetime.now().year

    lines = text.strip().split('\n')
    data = []

    for line in lines:
        line = line.strip()

        # Suicaåˆ©ç”¨è¨˜éŒ²ã®å½¢å¼ã‚’æ¤œå‡º: "05 01 å…¥ æˆ¸è¶ŠéŠ€åº§ å‡º æ±æ€¥äº”å -140"
        # æ­£è¦è¡¨ç¾ã§æœˆæ—¥ã¨è¨˜éŒ²ã‚’åŒæ™‚ã«æŠ½å‡º
        suica_pattern = r'^(\d{2})\s+(\d{2})\s+(.+?)\s+(-\d{1,3}(?:,\d{3})*)$'
        match = re.match(suica_pattern, line)

        if match:
            month = int(match.group(1))
            day = int(match.group(2))
            record = match.group(3)
            amount_str = match.group(4)

            # æŒ‡å®šã—ãŸå¹´æœˆã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
            if month != target_month:
                continue

            # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
            if any(keyword in record for keyword in exclude_keywords):
                continue

            # æœ‰åŠ¹ãªé§…ãƒ»ãƒã‚¹ã‹ãƒã‚§ãƒƒã‚¯
            is_valid = False

            # ãƒã‚¹åˆ©ç”¨ã‹ã©ã†ã‹ã‚’åˆ¤å®šï¼ˆã€Œãƒã‚¹ã€ã‚’å«ã‚€å ´åˆï¼‰
            is_bus = "ãƒã‚¹" in record

            if is_bus:
                # ãƒã‚¹ã®å ´åˆï¼šãƒã‚¹äº‹æ¥­è€…ãŒæŒ‡å®šé§…ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                # recordå†…ã‹ã‚‰ãƒã‚¹äº‹æ¥­è€…åã‚’æŠ½å‡º
                bus_companies = [station for station in valid_stations if "ãƒã‚¹" in station]
                is_valid = any(bus_company in record for bus_company in bus_companies)
            elif "å…¥" in record and "å‡º" in record:
                # é§…é–“ç§»å‹•ã®å ´åˆï¼šèµ·ç‚¹ã¾ãŸã¯çµ‚ç‚¹ã®ã„ãšã‚Œã‹ãŒæŒ‡å®šé§…ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                parts = record.split()
                from_station = ""
                to_station = ""

                # ã€Œå…¥ã€ã®æ¬¡ã®è¦ç´ ãŒèµ·ç‚¹é§…ã€ã€Œå‡ºã€ã®æ¬¡ã®è¦ç´ ãŒçµ‚ç‚¹é§…
                for i, part in enumerate(parts):
                    if part == "å…¥" or part == "ï¼Šå…¥" and i + 1 < len(parts):
                        from_station = parts[i + 1]
                    elif part == "å‡º" and i + 1 < len(parts):
                        to_station = parts[i + 1]

                # èµ·ç‚¹ã¾ãŸã¯çµ‚ç‚¹ã®ã„ãšã‚Œã‹ãŒæŒ‡å®šé§…ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆãƒã‚¹äº‹æ¥­è€…ã¯é™¤å¤–ï¼‰
                station_list = [station for station in valid_stations if "ãƒã‚¹" not in station]
                from_valid = any(station in from_station for station in station_list)
                to_valid = any(station in to_station for station in station_list)

                # ANDæ¡ä»¶ï¼šèµ·ç‚¹ã¨çµ‚ç‚¹ã®ä¸¡æ–¹ãŒæŒ‡å®šé§…ã«å«ã¾ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚‹
                is_valid = from_valid and to_valid
            else:
                # ãã®ä»–ã®å ´åˆï¼ˆé€šå¸¸ã¯ãªã„ãŒå¿µã®ãŸã‚ï¼‰
                is_valid = any(station in record for station in valid_stations)

            if is_valid:
                # é‡‘é¡ã‚’æ•°å€¤ã«å¤‰æ›
                amount = int(amount_str.replace('-', '').replace(',', ''))

                # æ‘˜è¦ã‚’ç”Ÿæˆ
                if is_bus:
                    # ãƒã‚¹åˆ©ç”¨ã®å ´åˆã€äº‹æ¥­è€…åã‚’æŠ½å‡º
                    bus_companies = [station for station in valid_stations if "ãƒã‚¹" in station and station in record]
                    if bus_companies:
                        summary = bus_companies[0]  # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸäº‹æ¥­è€…åã‚’ä½¿ç”¨
                    else:
                        summary = "ãƒã‚¹"  # ãƒã‚¹äº‹æ¥­è€…ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                elif "å…¥" in record and "å‡º" in record:
                    # é§…é–“ç§»å‹•ã®å ´åˆ
                    parts = record.split()
                    from_station = ""
                    to_station = ""

                    # ã€Œå…¥ã€ã®æ¬¡ã®è¦ç´ ãŒèµ·ç‚¹é§…ã€ã€Œå‡ºã€ã®æ¬¡ã®è¦ç´ ãŒçµ‚ç‚¹é§…
                    for i, part in enumerate(parts):
                        if part == "å…¥" or part == "ï¼Šå…¥" and i + 1 < len(parts):
                            from_station = parts[i + 1]
                        elif part == "å‡º" and i + 1 < len(parts):
                            to_station = parts[i + 1]

                    if from_station and to_station:
                        summary = f"{from_station} -> {to_station}"
                    else:
                        summary = "ç§»å‹•"
                else:
                    summary = "äº¤é€šè²»"

                data.append({
                    "æœˆ": f"{month:02d}",
                    "æ—¥": f"{day:02d}",
                    "æ°å": user_name,
                    "æ”¯æ‰•å…ˆ": "SUICA",
                    "æ‘˜è¦": summary,
                    "å‹˜å®šç§‘ç›®å": "äº¤é€šè²»",
                    "é‡‘é¡": amount
                })

    return pd.DataFrame(data)

def get_weekends_for_month(year, month):
    """æŒ‡å®šã•ã‚ŒãŸå¹´æœˆã®åœŸæ—¥ã‚’å–å¾—"""
    weekends = []

    # ãã®æœˆã®æ—¥æ•°ã‚’å–å¾—
    days_in_month = calendar.monthrange(year, month)[1]

    for day in range(1, days_in_month + 1):
        # æ›œæ—¥ã‚’å–å¾— (0=æœˆæ›œæ—¥, 6=æ—¥æ›œæ—¥)
        weekday = calendar.weekday(year, month, day)

        # åœŸæ›œæ—¥(5)ã¾ãŸã¯æ—¥æ›œæ—¥(6)ã®å ´åˆ
        if weekday >= 5:
            weekends.append(day)

    return weekends

def filter_weekdays(df, target_year, target_month):
    """æŒ‡å®šã•ã‚ŒãŸå¹´æœˆã®åœŸæ—¥ã‚’é™¤å¤–"""
    if len(df) == 0:
        return df

    # å‹•çš„ã«åœŸæ—¥ã‚’è¨ˆç®—
    weekends = get_weekends_for_month(target_year, target_month)

    try:
        # ã€Œæ—¥ã€åˆ—ã‹ã‚‰æ•°å­—ã®ã¿ã‚’æŠ½å‡º
        df_copy = df.copy()

        # å„å€¤ã‚’å€‹åˆ¥ã«å‡¦ç†ã—ã¦æ•°å­—ã®ã¿ã‚’æŠ½å‡º
        day_numbers = []
        for day_value in df_copy['æ—¥']:
            # æ–‡å­—åˆ—ã«å¤‰æ›
            day_str = str(day_value)
            # æ•°å­—ã®ã¿ã‚’æŠ½å‡º
            numbers = re.findall(r'\d+', day_str)
            if numbers:
                day_numbers.append(int(numbers[0]))
            else:
                # æ•°å­—ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯1ã‚’è¨­å®šï¼ˆå¹³æ—¥ã¨ã—ã¦æ‰±ã†ï¼‰
                day_numbers.append(1)

        df_copy['æ—¥_æ•°å€¤'] = day_numbers

        # åœŸæ—¥ã‚’é™¤å¤–
        filtered_df = df_copy[~df_copy['æ—¥_æ•°å€¤'].isin(weekends)].drop(columns=['æ—¥_æ•°å€¤'])

        return filtered_df

    except Exception as e:
        st.error(f"æ—¥ä»˜ã®å¤‰æ›ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return df

def main():
    st.set_page_config(
        page_title="Suicaäº¤é€šè²»ç”³è«‹CSVå¤‰æ›ãƒ„ãƒ¼ãƒ«",
        page_icon="ğŸšŠ",
        layout="wide"
    )

    st.title("ğŸšŠ Suicaäº¤é€šè²»ç”³è«‹CSVå¤‰æ›ãƒ„ãƒ¼ãƒ«")
    st.markdown("---")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'pdf_text' not in st.session_state:
        st.session_state.pdf_text = None
    if 'uploaded_filename' not in st.session_state:
        st.session_state.uploaded_filename = None

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")

        user_name = st.text_input("æ°å", value="ç”°ä¸­å¤ªéƒ")

        st.subheader("å¯¾è±¡é§…ãƒ»äº¤é€šæ©Ÿé–¢")
        default_stations = ["äº”åç”°"]
        stations_text = st.text_area(
            "å¯¾è±¡é§…ãƒ»äº¤é€šæ©Ÿé–¢ï¼ˆ1è¡Œã«1ã¤ãšã¤å…¥åŠ›ï¼‰",
            value="\n".join(default_stations),
            height=100,
            help="é§…åã‚„ãƒã‚¹äº‹æ¥­è€…åï¼ˆä¾‹ï¼šæ±æ€¥ãƒã‚¹ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        valid_stations = [station.strip() for station in stations_text.split('\n') if station.strip()]

        st.subheader("å¯¾è±¡æœŸé–“")
        col1, col2 = st.columns(2)
        with col1:
            target_year = st.number_input("å¯¾è±¡å¹´", min_value=2020, max_value=2030, value=datetime.now().year)
        with col2:
            target_month = st.number_input("å¯¾è±¡æœˆ", min_value=1, max_value=12, value=5)

        # åœŸæ—¥é™¤å¤–è¨­å®š
        st.subheader("åœŸæ—¥é™¤å¤–è¨­å®š")
        exclude_weekends = st.checkbox("åœŸæ—¥ã‚’é™¤å¤–", value=True, help=f"{target_year}å¹´{target_month}æœˆã®åœŸæ—¥ã‚’è‡ªå‹•çš„ã«é™¤å¤–ã—ã¾ã™")

        # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¨­å®š
        st.subheader("é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
        default_exclude_keywords = ["ç‰©è²©", "ï½¶ï½°ï¾„ï¾", "ãƒ¢ãƒã‚¤ãƒ«"]
        exclude_keywords_text = st.text_area(
            "é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ1è¡Œã«1ã¤ãšã¤å…¥åŠ›ï¼‰",
            value="\n".join(default_exclude_keywords),
            height=80,
            help="ã“ã“ã«å…¥åŠ›ã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€è¨˜éŒ²ã¯é™¤å¤–ã•ã‚Œã¾ã™"
        )
        exclude_keywords = [kw.strip() for kw in exclude_keywords_text.split('\n') if kw.strip()]

        # è¨­å®šã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        with st.expander("ç¾åœ¨ã®è¨­å®š"):
            st.write("**å¯¾è±¡é§…ãƒ»äº¤é€šæ©Ÿé–¢:**", valid_stations)
            st.write("**å¯¾è±¡æœŸé–“:**", f"{target_year}å¹´{target_month}æœˆ")
            st.write("**åœŸæ—¥é™¤å¤–:**", exclude_weekends)
            st.write("**é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:**", exclude_keywords)

    # ãƒ¡ã‚¤ãƒ³ç”»é¢
    col1, col2 = st.columns([1, 1])

    with col1:
        st.header("ğŸ“„ PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

        uploaded_file = st.file_uploader(
            "Suicaåˆ©ç”¨å±¥æ­´PDFã‚’é¸æŠ",
            type=['pdf']
        )

        # PDFãƒ†ã‚­ã‚¹ãƒˆã®å–å¾—ï¼ˆæ–°è¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰
        text_to_process = None

        if uploaded_file is not None:
            # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå ´åˆ
            if st.session_state.uploaded_filename != uploaded_file.name:
                try:
                    with st.spinner("PDFã‚’è§£æä¸­..."):
                        text_to_process = extract_text_from_pdf(uploaded_file)
                        st.session_state.pdf_text = text_to_process
                        st.session_state.uploaded_filename = uploaded_file.name
                except Exception as e:
                    st.error(f"âŒ PDFã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    text_to_process = None
            else:
                # æ—¢ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                text_to_process = st.session_state.pdf_text
        elif st.session_state.pdf_text is not None:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã¯ç©ºã ãŒã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
            text_to_process = st.session_state.pdf_text

        # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        df = pd.DataFrame()

        if text_to_process is not None:
            try:
                # ãƒ‡ãƒ¼ã‚¿å¤‰æ›
                with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›ä¸­..."):
                    df = parse_suica_data(text_to_process, user_name, valid_stations, target_year, target_month, exclude_keywords)

                    if exclude_weekends:
                        df = filter_weekdays(df, target_year, target_month)

                if len(df) > 0:
                    st.success(f"âœ… {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º")
                else:
                    st.warning("âš ï¸ å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            except Exception as e:
                st.error(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                df = pd.DataFrame()

    with col2:
        st.header("ğŸ“Š å¤‰æ›çµæœ")

        if len(df) > 0:
            # ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
            st.dataframe(df, use_container_width=True)

            # åˆè¨ˆé‡‘é¡
            total_amount = df['é‡‘é¡'].sum()
            st.metric("ğŸ’° åˆè¨ˆé‡‘é¡", f"{total_amount:,}å††")

            # CSVç”Ÿæˆ
            csv_buffer = io.StringIO()
            df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
            csv_data = csv_buffer.getvalue()

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            current_date = datetime.now().strftime("%Y%m%d")
            filename = f"äº¤é€šè²»ç”³è«‹_{current_date}.csv"

            st.download_button(
                label="ğŸ“¥ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_data,
                file_name=filename,
                mime='text/csv',
                type="primary"
            )

            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨CSVè¡¨ç¤º
            with st.expander("CSVãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                st.code(csv_data, language="csv")

        elif st.session_state.pdf_text is not None:
            st.info("è¨­å®šã‚’èª¿æ•´ã™ã‚‹ã¨è‡ªå‹•çš„ã«å†è¨ˆç®—ã•ã‚Œã¾ã™")
        else:
            st.info("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown(
        """
        **ä½¿ã„æ–¹:**
        1. å·¦å´ã§PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        2. å¿…è¦ã«å¿œã˜ã¦è¨­å®šã‚’èª¿æ•´ï¼ˆè‡ªå‹•çš„ã«å†è¨ˆç®—ã•ã‚Œã¾ã™ï¼‰
        3. å³å´ã§çµæœã‚’ç¢ºèªã—ã¦CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

        **æ³¨æ„äº‹é …:**
        - ãƒ¢ãƒã‚¤ãƒ«Suicaã®åˆ©ç”¨å±¥æ­´PDFã«å¯¾å¿œ
        - æŒ‡å®šã—ãŸé§…ãƒ»äº¤é€šæ©Ÿé–¢ã®èµ·ç‚¹ãƒ»çµ‚ç‚¹ã‚’æŒã¤ç§»å‹•ã®ã¿ãŒå¯¾è±¡
        - åœŸæ—¥ã®åˆ©ç”¨ã¯é™¤å¤–å¯èƒ½
        - ä¸€åº¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯è¨­å®šå¤‰æ›´æ™‚ã«å†åˆ©ç”¨ã•ã‚Œã¾ã™
        """
    )

if __name__ == "__main__":
    main()
